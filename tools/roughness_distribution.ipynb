{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting roughness texture map analysis...\n",
      "Found 3 roughness map files: ['roughness_1.png', 'roughness_2.png', 'roughness_3.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing roughness maps:  33%|███▎      | 1/3 [00:04<00:09,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  roughness_1.png Statistics:\n",
      "    - Mean: 0.0168\n",
      "    - Median: 0.0118\n",
      "    - Std Dev: 0.0179\n",
      "    - Entropy: 3.6851\n",
      "    - Skewness: 3.1516\n",
      "    - Kurtosis: 29.5216\n",
      "    - Area %: Smooth=100.0%, Medium=0.0%, Rough=0.0%, Very Rough=0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing roughness maps:  67%|██████▋   | 2/3 [00:09<00:04,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  roughness_2.png Statistics:\n",
      "    - Mean: 0.0200\n",
      "    - Median: 0.0157\n",
      "    - Std Dev: 0.0209\n",
      "    - Entropy: 3.9063\n",
      "    - Skewness: 3.1881\n",
      "    - Kurtosis: 29.5187\n",
      "    - Area %: Smooth=100.0%, Medium=0.0%, Rough=0.0%, Very Rough=0.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing roughness maps: 100%|██████████| 3/3 [00:13<00:00,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  roughness_3.png Statistics:\n",
      "    - Mean: 0.0275\n",
      "    - Median: 0.0196\n",
      "    - Std Dev: 0.0291\n",
      "    - Entropy: 4.3368\n",
      "    - Skewness: 2.7726\n",
      "    - Kurtosis: 19.1373\n",
      "    - Area %: Smooth=100.0%, Medium=0.0%, Rough=0.0%, Very Rough=0.0%\n",
      "\n",
      "Successfully processed 3 roughness maps. Generating figures...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\antoi\\AppData\\Local\\Temp\\ipykernel_35352\\1703057997.py:628: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0.1, 1, 0.95])  # Adjust layout for the colorbar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All figures have been saved to the 'roughness_analysis_output' directory.\n",
      "\n",
      "Summary report saved to 'roughness_analysis_output\\roughness_analysis_summary.txt'.\n",
      "Analysis complete!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "# ============================\n",
    "# Constants\n",
    "# ============================\n",
    "ROUGHNESS_FILE_PATTERN = \"roughness_*.png\"  # File pattern to search for\n",
    "BINS = 500  # Number of bins for histograms\n",
    "OUTPUT_DIR = \"roughness_analysis_output\"  # Directory to save output figures\n",
    "COLOR_ROUGHNESS = 'slategray'\n",
    "COLOR_GRADIENT_X = 'teal'\n",
    "COLOR_GRADIENT_Y = 'darkorange'\n",
    "\n",
    "# ============================\n",
    "# Functions for processing roughness maps\n",
    "# ============================\n",
    "def load_and_normalize(file_path):\n",
    "    \"\"\"Load the image file and normalize pixel values to [0,1].\"\"\"\n",
    "    img = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)\n",
    "    if img is None:\n",
    "        raise IOError(f\"Image not found: {file_path}\")\n",
    "        \n",
    "    # Handle different image types\n",
    "    if len(img.shape) == 3:  # Color image\n",
    "        # Convert to grayscale if it's a color image\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        roughness = img_gray.astype(np.float32) / 255.0\n",
    "        original_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB for display\n",
    "    else:  # Already grayscale\n",
    "        roughness = img.astype(np.float32) / 255.0\n",
    "        original_img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)  # Convert to RGB for display\n",
    "        \n",
    "    return original_img, roughness\n",
    "\n",
    "def compute_gradients(roughness):\n",
    "    \"\"\"Compute the gradients of the roughness map.\"\"\"\n",
    "    # Compute gradients using Sobel operators\n",
    "    grad_x = cv2.Sobel(roughness, cv2.CV_32F, 1, 0, ksize=3)\n",
    "    grad_y = cv2.Sobel(roughness, cv2.CV_32F, 0, 1, ksize=3)\n",
    "    \n",
    "    # Normalize gradients to [-1, 1] range\n",
    "    if np.max(np.abs(grad_x)) > 0:\n",
    "        grad_x = grad_x / np.max(np.abs(grad_x))\n",
    "    if np.max(np.abs(grad_y)) > 0:\n",
    "        grad_y = grad_y / np.max(np.abs(grad_y))\n",
    "        \n",
    "    # Compute gradient magnitude\n",
    "    gradient_mag = np.sqrt(grad_x**2 + grad_y**2)\n",
    "    if np.max(gradient_mag) > 0:\n",
    "        gradient_mag = gradient_mag / np.max(gradient_mag)\n",
    "        \n",
    "    return grad_x, grad_y, gradient_mag\n",
    "\n",
    "def compute_statistics(roughness):\n",
    "    \"\"\"Compute statistical properties of the roughness map.\"\"\"\n",
    "    flat_roughness = roughness.flatten()\n",
    "    \n",
    "    # Basic statistics\n",
    "    mean = np.mean(flat_roughness)\n",
    "    median = np.median(flat_roughness)\n",
    "    std = np.std(flat_roughness)\n",
    "    min_val = np.min(flat_roughness)\n",
    "    max_val = np.max(flat_roughness)\n",
    "    \n",
    "    # Calculate percentiles (10%, 25%, 75%, 90%)\n",
    "    percentiles = np.percentile(flat_roughness, [10, 25, 75, 90])\n",
    "    \n",
    "    # Calculate entropy (measure of randomness)\n",
    "    hist, _ = np.histogram(flat_roughness, bins=256, range=(0, 1))\n",
    "    hist = hist / np.sum(hist)  # Normalize\n",
    "    non_zero_hist = hist[hist > 0]\n",
    "    entropy = -np.sum(non_zero_hist * np.log2(non_zero_hist)) if len(non_zero_hist) > 0 else 0\n",
    "    \n",
    "    # Calculate percentage of areas with different roughness levels\n",
    "    roughness_areas = {\n",
    "        'smooth': np.mean(roughness < 0.25) * 100,     # Smooth areas (0-0.25)\n",
    "        'medium': np.mean((roughness >= 0.25) & (roughness < 0.5)) * 100,  # Medium roughness (0.25-0.5)\n",
    "        'rough': np.mean((roughness >= 0.5) & (roughness < 0.75)) * 100,   # Rough areas (0.5-0.75)\n",
    "        'very_rough': np.mean(roughness >= 0.75) * 100  # Very rough areas (0.75-1.0)\n",
    "    }\n",
    "    \n",
    "    # Add texture metrics\n",
    "    # Skewness (measure of asymmetry)\n",
    "    skewness = stats.skew(flat_roughness)\n",
    "    \n",
    "    # Kurtosis (measure of \"tailedness\")\n",
    "    kurtosis = stats.kurtosis(flat_roughness)\n",
    "    \n",
    "    # Calculate energy (measure of uniformity)\n",
    "    energy = np.sum(hist**2)\n",
    "    \n",
    "    stats_dict = {\n",
    "        'mean': mean,\n",
    "        'median': median,\n",
    "        'std': std,\n",
    "        'min': min_val,\n",
    "        'max': max_val,\n",
    "        'percentiles': percentiles,\n",
    "        'entropy': entropy,\n",
    "        'skewness': skewness,\n",
    "        'kurtosis': kurtosis,\n",
    "        'energy': energy,\n",
    "        'roughness_areas': roughness_areas\n",
    "    }\n",
    "    \n",
    "    return stats_dict\n",
    "\n",
    "def compute_fourier_analysis(roughness):\n",
    "    \"\"\"Compute Fourier transform to analyze frequency components.\"\"\"\n",
    "    # Apply FFT\n",
    "    f_transform = np.fft.fft2(roughness)\n",
    "    f_shift = np.fft.fftshift(f_transform)\n",
    "    \n",
    "    # Calculate the magnitude spectrum (log scale for better visualization)\n",
    "    magnitude_spectrum = 20 * np.log(np.abs(f_shift) + 1)\n",
    "    \n",
    "    # Normalize for display\n",
    "    if np.max(magnitude_spectrum) > 0:\n",
    "        normalized_spectrum = magnitude_spectrum / np.max(magnitude_spectrum)\n",
    "    else:\n",
    "        normalized_spectrum = magnitude_spectrum\n",
    "        \n",
    "    return normalized_spectrum\n",
    "\n",
    "def process_roughness_map(file_path):\n",
    "    \"\"\"Process a single roughness map file.\"\"\"\n",
    "    try:\n",
    "        # Load and normalize the image\n",
    "        original_img, roughness = load_and_normalize(file_path)\n",
    "        \n",
    "        # Compute gradients\n",
    "        grad_x, grad_y, gradient_mag = compute_gradients(roughness)\n",
    "        \n",
    "        # Compute statistics\n",
    "        stats_dict = compute_statistics(roughness)\n",
    "        \n",
    "        # Compute frequency analysis\n",
    "        frequency_spectrum = compute_fourier_analysis(roughness)\n",
    "        \n",
    "        # Create a result dictionary with all the data\n",
    "        result = {\n",
    "            'file_path': file_path,\n",
    "            'original_img': original_img,\n",
    "            'roughness': roughness,\n",
    "            'gradient_x': grad_x,\n",
    "            'gradient_y': grad_y,\n",
    "            'gradient_mag': gradient_mag,\n",
    "            'frequency_spectrum': frequency_spectrum,\n",
    "            'stats': stats_dict\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# ============================\n",
    "# Functions for plotting\n",
    "# ============================\n",
    "def get_global_min_max_y(results, hist_type):\n",
    "    \"\"\"Determine global y-axis limits for histograms to ensure consistent scales.\"\"\"\n",
    "    max_density = 0\n",
    "    \n",
    "    if hist_type == 'roughness':\n",
    "        for result in results:\n",
    "            hist, _ = np.histogram(result['roughness'].flatten(), bins=BINS, density=True)\n",
    "            max_density = max(max_density, np.max(hist))\n",
    "    elif hist_type == 'gradient':\n",
    "        for result in results:\n",
    "            for gradient in [result['gradient_x'], result['gradient_y']]:\n",
    "                hist, _ = np.histogram(gradient.flatten(), bins=BINS, density=True)\n",
    "                max_density = max(max_density, np.max(hist))\n",
    "    \n",
    "    # Add a small buffer (15%) to the max value for better visualization\n",
    "    max_density *= 1.15\n",
    "    \n",
    "    return (0, max_density)\n",
    "\n",
    "def plot_roughness_maps(results):\n",
    "    \"\"\"Plot each roughness map with its histogram and gradient magnitude.\"\"\"\n",
    "    n_images = len(results)\n",
    "    fig, axs = plt.subplots(n_images, 3, figsize=(18, 6 * n_images))\n",
    "    if n_images == 1:\n",
    "        axs = np.expand_dims(axs, axis=0)\n",
    "        \n",
    "    # Get global y-axis limits for roughness histograms\n",
    "    roughness_ylim = get_global_min_max_y(results, 'roughness')\n",
    "    \n",
    "    # Calculate max dimensions to ensure consistent zoom levels\n",
    "    all_heights = []\n",
    "    all_widths = []\n",
    "    for result in results:\n",
    "        h, w, _ = result['original_img'].shape\n",
    "        all_heights.append(h)\n",
    "        all_widths.append(w)\n",
    "    \n",
    "    max_height = max(all_heights)\n",
    "    max_width = max(all_widths)\n",
    "    \n",
    "    for idx, result in enumerate(results):\n",
    "        filename = os.path.basename(result['file_path'])\n",
    "        stats = result['stats']\n",
    "        \n",
    "        # Display the roughness map image\n",
    "        ax_img = axs[idx, 0]\n",
    "        ax_img.imshow(result['original_img'])\n",
    "        ax_img.set_title(f\"Roughness Map\\n{filename}\")\n",
    "        \n",
    "        # Ensure consistent zoom level across all images\n",
    "        h, w, _ = result['original_img'].shape\n",
    "        x_center = w / 2\n",
    "        y_center = h / 2\n",
    "        ax_img.set_xlim(x_center - max_width/2, x_center + max_width/2)\n",
    "        ax_img.set_ylim(y_center + max_height/2, y_center - max_height/2)\n",
    "        \n",
    "        ax_img.set_aspect('equal')\n",
    "        ax_img.axis(\"off\")\n",
    "        \n",
    "        # Roughness histogram\n",
    "        ax_hist = axs[idx, 1]\n",
    "        sns.histplot(result['roughness'].flatten(), bins=BINS, kde=True, \n",
    "                    color=COLOR_ROUGHNESS, edgecolor='black', alpha=0.7, ax=ax_hist)\n",
    "        ax_hist.set_xlabel(\"Roughness Value\")\n",
    "        ax_hist.set_ylabel(\"Probability Density\")\n",
    "        ax_hist.set_title(f\"Roughness Distribution - {filename}\")\n",
    "        ax_hist.set_xlim(0, 1)\n",
    "        ax_hist.set_ylim(*roughness_ylim)\n",
    "        ax_hist.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add mean and median lines\n",
    "        ax_hist.axvline(stats['mean'], color='red', linestyle='-', linewidth=2, \n",
    "                      label=f'Mean: {stats[\"mean\"]:.3f}')\n",
    "        ax_hist.axvline(stats['median'], color='green', linestyle='--', linewidth=2, \n",
    "                      label=f'Median: {stats[\"median\"]:.3f}')\n",
    "        \n",
    "        # Add percentile lines\n",
    "        ax_hist.axvline(stats['percentiles'][0], color='purple', linestyle=':', linewidth=1,\n",
    "                      label=f'10th %: {stats[\"percentiles\"][0]:.3f}')\n",
    "        ax_hist.axvline(stats['percentiles'][3], color='orange', linestyle=':', linewidth=1,\n",
    "                      label=f'90th %: {stats[\"percentiles\"][3]:.3f}')\n",
    "        \n",
    "        ax_hist.legend(loc='upper right', fontsize='small')\n",
    "        \n",
    "        # Gradient magnitude visualization\n",
    "        ax_grad = axs[idx, 2]\n",
    "        im = ax_grad.imshow(result['gradient_mag'], cmap='hot', vmin=0, vmax=1)\n",
    "        ax_grad.set_title(f\"Gradient Magnitude - {filename}\")\n",
    "        \n",
    "        # Ensure consistent zoom level for gradient maps too\n",
    "        ax_grad.set_xlim(x_center - max_width/2, x_center + max_width/2)\n",
    "        ax_grad.set_ylim(y_center + max_height/2, y_center - max_height/2)\n",
    "        \n",
    "        ax_grad.set_aspect('equal')\n",
    "        ax_grad.axis(\"off\")\n",
    "        \n",
    "        # Add colorbar\n",
    "        plt.colorbar(im, ax=ax_grad, orientation='vertical', label='Gradient Magnitude')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_gradient_histograms(results):\n",
    "    \"\"\"Plot histograms of the x and y gradients for each roughness map.\"\"\"\n",
    "    n_images = len(results)\n",
    "    fig, axs = plt.subplots(n_images, 2, figsize=(14, 5 * n_images))\n",
    "    if n_images == 1:\n",
    "        axs = np.expand_dims(axs, axis=0)\n",
    "        \n",
    "    # Get global y-axis limits for gradient histograms\n",
    "    gradient_ylim = get_global_min_max_y(results, 'gradient')\n",
    "    \n",
    "    for idx, result in enumerate(results):\n",
    "        filename = os.path.basename(result['file_path'])\n",
    "        \n",
    "        # X gradient histogram\n",
    "        ax_x = axs[idx, 0]\n",
    "        sns.histplot(result['gradient_x'].flatten(), bins=BINS, kde=True,\n",
    "                   color=COLOR_GRADIENT_X, edgecolor='black', alpha=0.7, ax=ax_x)\n",
    "        ax_x.set_xlabel(\"X Gradient Value\")\n",
    "        ax_x.set_ylabel(\"Probability Density\")\n",
    "        ax_x.set_title(f\"X Gradient Distribution - {filename}\")\n",
    "        ax_x.set_xlim(-1, 1)\n",
    "        ax_x.set_ylim(*gradient_ylim)\n",
    "        ax_x.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Y gradient histogram\n",
    "        ax_y = axs[idx, 1]\n",
    "        sns.histplot(result['gradient_y'].flatten(), bins=BINS, kde=True,\n",
    "                   color=COLOR_GRADIENT_Y, edgecolor='black', alpha=0.7, ax=ax_y)\n",
    "        ax_y.set_xlabel(\"Y Gradient Value\")\n",
    "        ax_y.set_ylabel(\"Probability Density\")\n",
    "        ax_y.set_title(f\"Y Gradient Distribution - {filename}\")\n",
    "        ax_y.set_xlim(-1, 1)\n",
    "        ax_y.set_ylim(*gradient_ylim)\n",
    "        ax_y.grid(True, alpha=0.3)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_frequency_analysis(results):\n",
    "    \"\"\"Plot frequency domain visualization for each roughness map.\"\"\"\n",
    "    n_images = len(results)\n",
    "    fig, axs = plt.subplots(n_images, 2, figsize=(14, 6 * n_images))\n",
    "    if n_images == 1:\n",
    "        axs = np.expand_dims(axs, axis=0)\n",
    "    \n",
    "    # Calculate max dimensions for consistent zoom\n",
    "    all_heights = []\n",
    "    all_widths = []\n",
    "    for result in results:\n",
    "        h, w = result['frequency_spectrum'].shape\n",
    "        all_heights.append(h)\n",
    "        all_widths.append(w)\n",
    "    \n",
    "    max_height = max(all_heights)\n",
    "    max_width = max(all_widths)\n",
    "        \n",
    "    for idx, result in enumerate(results):\n",
    "        filename = os.path.basename(result['file_path'])\n",
    "        \n",
    "        # Original roughness map\n",
    "        ax_orig = axs[idx, 0]\n",
    "        ax_orig.imshow(result['roughness'], cmap='gray')\n",
    "        ax_orig.set_title(f\"Roughness Map - {filename}\")\n",
    "        \n",
    "        # Ensure consistent zoom\n",
    "        h, w = result['roughness'].shape\n",
    "        x_center = w / 2\n",
    "        y_center = h / 2\n",
    "        ax_orig.set_xlim(x_center - max_width/2, x_center + max_width/2)\n",
    "        ax_orig.set_ylim(y_center + max_height/2, y_center - max_height/2)\n",
    "        \n",
    "        ax_orig.set_aspect('equal')\n",
    "        ax_orig.axis(\"off\")\n",
    "        \n",
    "        # Frequency spectrum\n",
    "        ax_freq = axs[idx, 1]\n",
    "        im = ax_freq.imshow(result['frequency_spectrum'], cmap='viridis')\n",
    "        ax_freq.set_title(f\"Frequency Spectrum - {filename}\")\n",
    "        \n",
    "        # Ensure consistent zoom for frequency maps too\n",
    "        h, w = result['frequency_spectrum'].shape\n",
    "        x_center = w / 2\n",
    "        y_center = h / 2\n",
    "        ax_freq.set_xlim(x_center - max_width/2, x_center + max_width/2)\n",
    "        ax_freq.set_ylim(y_center + max_height/2, y_center - max_height/2)\n",
    "        \n",
    "        ax_freq.set_aspect('equal')\n",
    "        ax_freq.axis(\"off\")\n",
    "        \n",
    "        # Add colorbar\n",
    "        plt.colorbar(im, ax=ax_freq, orientation='vertical', label='Magnitude (dB)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_roughness_statistics(results):\n",
    "    \"\"\"Plot how roughness statistics change per frame.\"\"\"\n",
    "    # Sort results by frame number\n",
    "    # Try to extract the numeric part from the filename\n",
    "    def extract_number(file_path):\n",
    "        # Attempt to extract the number from patterns like \"roughness_1.png\" or \"1.png\"\n",
    "        base_name = os.path.basename(file_path)\n",
    "        name_parts = base_name.split('_')\n",
    "        \n",
    "        # If there's an underscore, take the last part, otherwise use the whole filename\n",
    "        num_part = name_parts[-1] if len(name_parts) > 1 else base_name\n",
    "        \n",
    "        # Remove file extension and convert to int\n",
    "        num_str = os.path.splitext(num_part)[0]\n",
    "        \n",
    "        # Try to extract a number, default to 0 if no number found\n",
    "        try:\n",
    "            return int(''.join(filter(str.isdigit, num_str)))\n",
    "        except ValueError:\n",
    "            return 0\n",
    "    \n",
    "    sorted_results = sorted(results, key=lambda r: extract_number(r['file_path']))\n",
    "    \n",
    "    frames = list(range(1, len(sorted_results) + 1))\n",
    "    file_names = [os.path.basename(r['file_path']) for r in sorted_results]\n",
    "    \n",
    "    # Extract statistics\n",
    "    means = [r['stats']['mean'] for r in sorted_results]\n",
    "    medians = [r['stats']['median'] for r in sorted_results]\n",
    "    stds = [r['stats']['std'] for r in sorted_results]\n",
    "    entropies = [r['stats']['entropy'] for r in sorted_results]\n",
    "    skewness = [r['stats']['skewness'] for r in sorted_results]\n",
    "    kurtosis = [r['stats']['kurtosis'] for r in sorted_results]\n",
    "    energy = [r['stats']['energy'] for r in sorted_results]\n",
    "    \n",
    "    # Create figure with 4 subplots\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Get proper y-axis ranges for better visualization\n",
    "    mean_range = max(means) - min(means)\n",
    "    mean_padding = mean_range * 0.1\n",
    "    mean_min = max(0, min(means) - mean_padding)\n",
    "    mean_max = min(1, max(means) + mean_padding)\n",
    "    \n",
    "    # Plot mean and median\n",
    "    ax_central = axs[0, 0]\n",
    "    ax_central.plot(frames, means, 'o-', color='red', linewidth=2, label='Mean')\n",
    "    ax_central.plot(frames, medians, 's--', color='green', linewidth=2, label='Median')\n",
    "    ax_central.set_xlabel(\"Frame\")\n",
    "    ax_central.set_ylabel(\"Value\")\n",
    "    ax_central.set_title(\"Mean and Median Roughness\")\n",
    "    ax_central.set_xticks(frames)\n",
    "    ax_central.set_xticklabels(file_names, rotation=45)\n",
    "    ax_central.set_ylim(mean_min, mean_max)\n",
    "    ax_central.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax_central.legend()\n",
    "    \n",
    "    # Plot standard deviation\n",
    "    ax_std = axs[0, 1]\n",
    "    ax_std.plot(frames, stds, 'o-', color='purple', linewidth=2)\n",
    "    ax_std.set_xlabel(\"Frame\")\n",
    "    ax_std.set_ylabel(\"Standard Deviation\")\n",
    "    ax_std.set_title(\"Roughness Variation (Standard Deviation)\")\n",
    "    ax_std.set_xticks(frames)\n",
    "    ax_std.set_xticklabels(file_names, rotation=45)\n",
    "    # Set y-axis limits for better visualization\n",
    "    std_max = max(stds) * 1.1\n",
    "    ax_std.set_ylim(0, std_max)\n",
    "    ax_std.grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "    # Plot entropy\n",
    "    ax_entropy = axs[1, 0]\n",
    "    ax_entropy.plot(frames, entropies, 'o-', color='blue', linewidth=2)\n",
    "    ax_entropy.set_xlabel(\"Frame\")\n",
    "    ax_entropy.set_ylabel(\"Entropy\")\n",
    "    ax_entropy.set_title(\"Surface Complexity (Entropy)\")\n",
    "    ax_entropy.set_xticks(frames)\n",
    "    ax_entropy.set_xticklabels(file_names, rotation=45)\n",
    "    # Set y-axis limits for better visualization\n",
    "    entropy_min = min(entropies) * 0.9\n",
    "    entropy_max = max(entropies) * 1.1\n",
    "    ax_entropy.set_ylim(entropy_min, entropy_max)\n",
    "    ax_entropy.grid(True, linestyle='--', alpha=0.6)\n",
    "    \n",
    "    # Plot roughness area distribution\n",
    "    ax_areas = axs[1, 1]\n",
    "    smooth_areas = [r['stats']['roughness_areas']['smooth'] for r in sorted_results]\n",
    "    medium_areas = [r['stats']['roughness_areas']['medium'] for r in sorted_results]\n",
    "    rough_areas = [r['stats']['roughness_areas']['rough'] for r in sorted_results]\n",
    "    very_rough_areas = [r['stats']['roughness_areas']['very_rough'] for r in sorted_results]\n",
    "    \n",
    "    ax_areas.stackplot(frames, \n",
    "                     smooth_areas, \n",
    "                     medium_areas, \n",
    "                     rough_areas, \n",
    "                     very_rough_areas,\n",
    "                     labels=['Smooth (0-0.25)', 'Medium (0.25-0.5)', 'Rough (0.5-0.75)', 'Very Rough (0.75-1.0)'],\n",
    "                     colors=['skyblue', 'lightgreen', 'orange', 'tomato'],\n",
    "                     alpha=0.8)\n",
    "    ax_areas.set_xlabel(\"Frame\")\n",
    "    ax_areas.set_ylabel(\"Percentage\")\n",
    "    ax_areas.set_title(\"Roughness Area Distribution\")\n",
    "    ax_areas.set_xticks(frames)\n",
    "    ax_areas.set_xticklabels(file_names, rotation=45)\n",
    "    ax_areas.set_ylim(0, 100)\n",
    "    ax_areas.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax_areas.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_advanced_statistics(results):\n",
    "    \"\"\"Plot advanced statistical measures across frames.\"\"\"\n",
    "    # Sort results same as in plot_roughness_statistics\n",
    "    def extract_number(file_path):\n",
    "        base_name = os.path.basename(file_path)\n",
    "        name_parts = base_name.split('_')\n",
    "        num_part = name_parts[-1] if len(name_parts) > 1 else base_name\n",
    "        num_str = os.path.splitext(num_part)[0]\n",
    "        try:\n",
    "            return int(''.join(filter(str.isdigit, num_str)))\n",
    "        except ValueError:\n",
    "            return 0\n",
    "    \n",
    "    sorted_results = sorted(results, key=lambda r: extract_number(r['file_path']))\n",
    "    \n",
    "    frames = list(range(1, len(sorted_results) + 1))\n",
    "    file_names = [os.path.basename(r['file_path']) for r in sorted_results]\n",
    "    \n",
    "    # Extract advanced statistics\n",
    "    skewness = [r['stats']['skewness'] for r in sorted_results]\n",
    "    kurtosis = [r['stats']['kurtosis'] for r in sorted_results]\n",
    "    energy = [r['stats']['energy'] for r in sorted_results]\n",
    "    \n",
    "    # Create figure with 3 subplots\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(14, 15))\n",
    "    \n",
    "    # Plot skewness (asymmetry)\n",
    "    ax_skew = axs[0]\n",
    "    ax_skew.plot(frames, skewness, 'o-', color='teal', linewidth=2)\n",
    "    ax_skew.set_xlabel(\"Frame\")\n",
    "    ax_skew.set_ylabel(\"Skewness\")\n",
    "    ax_skew.set_title(\"Distribution Asymmetry (Skewness)\")\n",
    "    ax_skew.set_xticks(frames)\n",
    "    ax_skew.set_xticklabels(file_names, rotation=45)\n",
    "    ax_skew.axhline(y=0, color='gray', linestyle='--', alpha=0.6)\n",
    "    ax_skew.grid(True, linestyle='--', alpha=0.6)\n",
    "    # Add annotation about meaning\n",
    "    ax_skew.annotate('Positive: More rough areas\\nNegative: More smooth areas', \n",
    "                    xy=(0.02, 0.85), xycoords='axes fraction',\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"lightyellow\", ec=\"orange\", alpha=0.8))\n",
    "    \n",
    "    # Plot kurtosis (peakedness)\n",
    "    ax_kurt = axs[1]\n",
    "    ax_kurt.plot(frames, kurtosis, 'o-', color='purple', linewidth=2)\n",
    "    ax_kurt.set_xlabel(\"Frame\")\n",
    "    ax_kurt.set_ylabel(\"Kurtosis\")\n",
    "    ax_kurt.set_title(\"Distribution Peakedness (Kurtosis)\")\n",
    "    ax_kurt.set_xticks(frames)\n",
    "    ax_kurt.set_xticklabels(file_names, rotation=45)\n",
    "    ax_kurt.axhline(y=0, color='gray', linestyle='--', alpha=0.6)\n",
    "    ax_kurt.grid(True, linestyle='--', alpha=0.6)\n",
    "    # Add annotation about meaning\n",
    "    ax_kurt.annotate('Positive: More extreme values\\nNegative: More uniform distribution', \n",
    "                    xy=(0.02, 0.85), xycoords='axes fraction',\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"lightyellow\", ec=\"orange\", alpha=0.8))\n",
    "    \n",
    "    # Plot energy (uniformity)\n",
    "    ax_energy = axs[2]\n",
    "    ax_energy.plot(frames, energy, 'o-', color='darkred', linewidth=2)\n",
    "    ax_energy.set_xlabel(\"Frame\")\n",
    "    ax_energy.set_ylabel(\"Energy\")\n",
    "    ax_energy.set_title(\"Texture Uniformity (Energy)\")\n",
    "    ax_energy.set_xticks(frames)\n",
    "    ax_energy.set_xticklabels(file_names, rotation=45)\n",
    "    ax_energy.grid(True, linestyle='--', alpha=0.6)\n",
    "    # Add annotation about meaning\n",
    "    ax_energy.annotate('Higher: More uniform texture\\nLower: More varied texture', \n",
    "                     xy=(0.02, 0.85), xycoords='axes fraction',\n",
    "                     bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"lightyellow\", ec=\"orange\", alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_comparative_analysis(results):\n",
    "    \"\"\"Create a comparative visualization of all roughness maps side by side.\"\"\"\n",
    "    # Sort results\n",
    "    def extract_number(file_path):\n",
    "        base_name = os.path.basename(file_path)\n",
    "        name_parts = base_name.split('_')\n",
    "        num_part = name_parts[-1] if len(name_parts) > 1 else base_name\n",
    "        num_str = os.path.splitext(num_part)[0]\n",
    "        try:\n",
    "            return int(''.join(filter(str.isdigit, num_str)))\n",
    "        except ValueError:\n",
    "            return 0\n",
    "    \n",
    "    sorted_results = sorted(results, key=lambda r: extract_number(r['file_path']))\n",
    "    \n",
    "    # Calculate the grid layout (try to make it square-ish)\n",
    "    n_images = len(sorted_results)\n",
    "    grid_size = int(np.ceil(np.sqrt(n_images)))\n",
    "    rows = grid_size\n",
    "    cols = grid_size\n",
    "    \n",
    "    # Create a large figure for the comparison\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=(cols*4, rows*4))\n",
    "    \n",
    "    # Calculate global min/max for colormap normalization\n",
    "    all_roughness = np.concatenate([r['roughness'].flatten() for r in sorted_results])\n",
    "    vmin, vmax = np.min(all_roughness), np.max(all_roughness)\n",
    "    \n",
    "    # Calculate max dimensions to ensure consistent zoom levels\n",
    "    all_heights = []\n",
    "    all_widths = []\n",
    "    for result in sorted_results:\n",
    "        h, w = result['roughness'].shape\n",
    "        all_heights.append(h)\n",
    "        all_widths.append(w)\n",
    "    \n",
    "    max_height = max(all_heights)\n",
    "    max_width = max(all_widths)\n",
    "    \n",
    "    # Make sure axs is always a 2D array\n",
    "    if rows == 1 and cols == 1:\n",
    "        axs = np.array([[axs]])\n",
    "    elif rows == 1:\n",
    "        axs = axs.reshape(1, -1)\n",
    "    elif cols == 1:\n",
    "        axs = axs.reshape(-1, 1)\n",
    "    \n",
    "    # Plot each roughness map with consistent colormap\n",
    "    for idx, result in enumerate(sorted_results):\n",
    "        if idx < rows * cols:\n",
    "            row = idx // cols\n",
    "            col = idx % cols\n",
    "            \n",
    "            ax = axs[row, col]\n",
    "            filename = os.path.basename(result['file_path'])\n",
    "            \n",
    "            # Plot the roughness map\n",
    "            im = ax.imshow(result['roughness'], cmap='viridis', vmin=vmin, vmax=vmax)\n",
    "            \n",
    "            # Ensure consistent zoom level\n",
    "            h, w = result['roughness'].shape\n",
    "            x_center = w / 2\n",
    "            y_center = h / 2\n",
    "            ax.set_xlim(x_center - max_width/2, x_center + max_width/2)\n",
    "            ax.set_ylim(y_center + max_height/2, y_center - max_height/2)\n",
    "            \n",
    "            ax.set_title(f\"{filename}\\nMean: {result['stats']['mean']:.3f}\")\n",
    "            ax.axis('off')\n",
    "            \n",
    "    # Turn off any unused subplots\n",
    "    for idx in range(n_images, rows*cols):\n",
    "        row = idx // cols\n",
    "        col = idx % cols\n",
    "        axs[row, col].axis('off')\n",
    "    \n",
    "    # Add a colorbar at the bottom\n",
    "    cbar_ax = fig.add_axes([0.15, 0.07, 0.7, 0.02])\n",
    "    cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal')\n",
    "    cbar.set_label('Roughness Value')\n",
    "    \n",
    "    plt.suptitle('Comparative Analysis of Roughness Maps', fontsize=20, y=0.98)\n",
    "    plt.tight_layout(rect=[0, 0.1, 1, 0.95])  # Adjust layout for the colorbar\n",
    "    return fig\n",
    "\n",
    "# ============================\n",
    "# Main function\n",
    "# ============================\n",
    "def analyze_roughness_maps(file_pattern=ROUGHNESS_FILE_PATTERN, output_dir=OUTPUT_DIR):\n",
    "    \"\"\"Analyze roughness texture maps.\"\"\"\n",
    "    print(\"Starting roughness texture map analysis...\")\n",
    "    \n",
    "    # Find all files matching the roughness file pattern\n",
    "    roughness_files = glob.glob(file_pattern)\n",
    "    if len(roughness_files) < 1:\n",
    "        print(f\"No roughness map images found matching pattern '{file_pattern}'.\")\n",
    "        return\n",
    "    \n",
    "    # Sort the files numerically\n",
    "    roughness_files = sorted(roughness_files, \n",
    "                           key=lambda f: int(''.join(filter(str.isdigit, os.path.splitext(os.path.basename(f))[0])) or 0))\n",
    "    \n",
    "    print(f\"Found {len(roughness_files)} roughness map files: {roughness_files}\")\n",
    "    \n",
    "    # Process each roughness map file with progress bar\n",
    "    results = []\n",
    "    for file in tqdm(roughness_files, desc=\"Processing roughness maps\"):\n",
    "        try:\n",
    "            result = process_roughness_map(file)\n",
    "            if result is not None:  # Only add valid results\n",
    "                results.append(result)\n",
    "                \n",
    "                # Print a summary of the statistics\n",
    "                stats = result['stats']\n",
    "                print(f\"\\n  {file} Statistics:\")\n",
    "                print(f\"    - Mean: {stats['mean']:.4f}\")\n",
    "                print(f\"    - Median: {stats['median']:.4f}\")\n",
    "                print(f\"    - Std Dev: {stats['std']:.4f}\")\n",
    "                print(f\"    - Entropy: {stats['entropy']:.4f}\")\n",
    "                print(f\"    - Skewness: {stats['skewness']:.4f}\")\n",
    "                print(f\"    - Kurtosis: {stats['kurtosis']:.4f}\")\n",
    "                print(f\"    - Area %: Smooth={stats['roughness_areas']['smooth']:.1f}%, \"\n",
    "                      f\"Medium={stats['roughness_areas']['medium']:.1f}%, \"\n",
    "                      f\"Rough={stats['roughness_areas']['rough']:.1f}%, \"\n",
    "                      f\"Very Rough={stats['roughness_areas']['very_rough']:.1f}%\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error in main loop processing {file}: {e}\")\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No valid roughness maps to process.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nSuccessfully processed {len(results)} roughness maps. Generating figures...\")\n",
    "    \n",
    "    # Create a directory for saving figures\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Set figure saving parameters\n",
    "    plt.rcParams['savefig.dpi'] = 300\n",
    "    plt.rcParams['figure.autolayout'] = True\n",
    "    \n",
    "    # Figure 1: Plot roughness maps with histograms\n",
    "    fig1 = plot_roughness_maps(results)\n",
    "    fig1.savefig(os.path.join(output_dir, \"figure1_roughness_maps.png\"))\n",
    "    plt.close(fig1)\n",
    "    \n",
    "    # Figure 2: Plot gradient histograms\n",
    "    fig2 = plot_gradient_histograms(results)\n",
    "    fig2.savefig(os.path.join(output_dir, \"figure2_gradient_histograms.png\"))\n",
    "    plt.close(fig2)\n",
    "    \n",
    "    # Figure 3: Plot frequency analysis\n",
    "    fig3 = plot_frequency_analysis(results)\n",
    "    fig3.savefig(os.path.join(output_dir, \"figure3_frequency_analysis.png\"))\n",
    "    plt.close(fig3)\n",
    "    \n",
    "    # Figure 4: Plot roughness statistics\n",
    "    fig4 = plot_roughness_statistics(results)\n",
    "    fig4.savefig(os.path.join(output_dir, \"figure4_roughness_statistics.png\"))\n",
    "    plt.close(fig4)\n",
    "    \n",
    "    # Figure 5: Plot advanced statistics\n",
    "    fig5 = plot_advanced_statistics(results)\n",
    "    fig5.savefig(os.path.join(output_dir, \"figure5_advanced_statistics.png\"))\n",
    "    plt.close(fig5)\n",
    "    \n",
    "    # Figure 6: Plot comparative analysis\n",
    "    fig6 = plot_comparative_analysis(results)\n",
    "    fig6.savefig(os.path.join(output_dir, \"figure6_comparative_analysis.png\"))\n",
    "    plt.close(fig6)\n",
    "    \n",
    "    print(f\"\\nAll figures have been saved to the '{output_dir}' directory.\")\n",
    "    \n",
    "    # Create a summary report with key metrics\n",
    "    create_summary_report(results, output_dir)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def create_summary_report(results, output_dir):\n",
    "    \"\"\"Create a summary report of the analysis.\"\"\"\n",
    "    summary_file = os.path.join(output_dir, \"roughness_analysis_summary.txt\")\n",
    "    \n",
    "    with open(summary_file, 'w') as f:\n",
    "        f.write(\"Roughness Analysis Summary Report\\n\")\n",
    "        f.write(\"=\" * 40 + \"\\n\")\n",
    "        for result in results:\n",
    "            filename = os.path.basename(result['file_path'])\n",
    "            stats = result['stats']\n",
    "            \n",
    "            f.write(f\"\\nFile: {filename}\\n\")\n",
    "            f.write(f\"Mean: {stats['mean']:.4f}\\n\")\n",
    "            f.write(f\"Median: {stats['median']:.4f}\\n\")\n",
    "            f.write(f\"Standard Deviation: {stats['std']:.4f}\\n\")\n",
    "            f.write(f\"Entropy: {stats['entropy']:.4f}\\n\")\n",
    "            f.write(f\"Skewness: {stats['skewness']:.4f}\\n\")\n",
    "            f.write(f\"Kurtosis: {stats['kurtosis']:.4f}\\n\")\n",
    "            f.write(f\"Energy: {stats['energy']:.4f}\\n\")\n",
    "            f.write(f\"Area %: Smooth={stats['roughness_areas']['smooth']:.1f}%, \"\n",
    "                    f\"Medium={stats['roughness_areas']['medium']:.1f}%, \"\n",
    "                    f\"Rough={stats['roughness_areas']['rough']:.1f}%, \"\n",
    "                    f\"Very Rough={stats['roughness_areas']['very_rough']:.1f}%\\n\")\n",
    "    \n",
    "    print(f\"\\nSummary report saved to '{summary_file}'.\")\n",
    "\n",
    "    print(\"Analysis complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the analysis with default parameters\n",
    "    analyze_roughness_maps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
