{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 192\u001b[0m\n\u001b[0;32m    189\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# Align and average images\u001b[39;00m\n\u001b[1;32m--> 192\u001b[0m avg_image, aligned_images \u001b[38;5;241m=\u001b[39m \u001b[43malign_and_average\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# Display results\u001b[39;00m\n\u001b[0;32m    195\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n",
      "Cell \u001b[1;32mIn[1], line 172\u001b[0m, in \u001b[0;36malign_and_average\u001b[1;34m(image_paths, levels, iterations, margin)\u001b[0m\n\u001b[0;32m    169\u001b[0m images \u001b[38;5;241m=\u001b[39m [cv2\u001b[38;5;241m.\u001b[39mimread(path) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m image_paths]\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# Align images\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m aligned_images \u001b[38;5;241m=\u001b[39m \u001b[43meulerian_motion_align\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# Crop images to remove border artifacts\u001b[39;00m\n\u001b[0;32m    175\u001b[0m cropped_images \u001b[38;5;241m=\u001b[39m crop_aligned_images(aligned_images, margin)\n",
      "Cell \u001b[1;32mIn[1], line 37\u001b[0m, in \u001b[0;36meulerian_motion_align\u001b[1;34m(images, levels, iterations)\u001b[0m\n\u001b[0;32m     34\u001b[0m aligned_images \u001b[38;5;241m=\u001b[39m [reference]\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Convert to grayscale for motion estimation if the images are in color\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mreference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m     38\u001b[0m     reference_gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(reference, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.ndimage import zoom\n",
    "from skimage.transform import warp, AffineTransform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gaussian_pyramid(image, levels=3):\n",
    "    \"\"\"Generate a Gaussian pyramid for the image.\"\"\"\n",
    "    pyramid = [image.copy()]\n",
    "    for i in range(levels-1):\n",
    "        image = cv2.pyrDown(image)\n",
    "        pyramid.append(image.copy())\n",
    "    return pyramid\n",
    "\n",
    "def eulerian_motion_align(images, levels=3, iterations=10):\n",
    "    \"\"\"\n",
    "    Align images using multi-scale Eulerian motion estimation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    images : list of numpy arrays\n",
    "        List of images to align\n",
    "    levels : int\n",
    "        Number of levels in the pyramid\n",
    "    iterations : int\n",
    "        Number of iterations per level\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    aligned_images : list of numpy arrays\n",
    "        List of aligned images\n",
    "    \"\"\"\n",
    "    reference = images[0]\n",
    "    aligned_images = [reference]\n",
    "    \n",
    "    # Convert to grayscale for motion estimation if the images are in color\n",
    "    if len(reference.shape) == 3:\n",
    "        reference_gray = cv2.cvtColor(reference, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        reference_gray = reference.copy()\n",
    "    \n",
    "    for i in range(1, len(images)):\n",
    "        moving = images[i].copy()\n",
    "        \n",
    "        # Convert to grayscale for motion estimation if the images are in color\n",
    "        if len(moving.shape) == 3:\n",
    "            moving_gray = cv2.cvtColor(moving, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            moving_gray = moving.copy()\n",
    "        \n",
    "        # Initialize transformation parameters\n",
    "        tx, ty, angle = 0, 0, 0\n",
    "        \n",
    "        # Build pyramids\n",
    "        ref_pyramid = gaussian_pyramid(reference_gray, levels)\n",
    "        mov_pyramid = gaussian_pyramid(moving_gray, levels)\n",
    "        \n",
    "        # Process from coarse to fine\n",
    "        for level in range(levels-1, -1, -1):\n",
    "            ref_level = ref_pyramid[level]\n",
    "            mov_level = mov_pyramid[level]\n",
    "            \n",
    "            # Scale the transformation parameters for the current level\n",
    "            scale_factor = 2 ** (levels - 1 - level)\n",
    "            current_tx = tx * scale_factor\n",
    "            current_ty = ty * scale_factor\n",
    "            \n",
    "            # Apply current transformation\n",
    "            tform = AffineTransform(rotation=np.deg2rad(angle), \n",
    "                                   translation=(current_tx, current_ty))\n",
    "            moved = warp(mov_level, tform.inverse, mode='edge')\n",
    "            \n",
    "            # Refine transformation at current level\n",
    "            for _ in range(iterations):\n",
    "                # Calculate optical flow using Lucas-Kanade method\n",
    "                flow = cv2.calcOpticalFlowFarneback(\n",
    "                    ref_level, moved, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "                \n",
    "                # Extract motion parameters\n",
    "                dy, dx = np.mean(flow, axis=(0, 1))\n",
    "                \n",
    "                # For rotation, we could use more sophisticated methods\n",
    "                # This is a simplified approach\n",
    "                y, x = np.mgrid[:flow.shape[0], :flow.shape[1]]\n",
    "                center_y, center_x = flow.shape[0] // 2, flow.shape[1] // 2\n",
    "                y = y - center_y\n",
    "                x = x - center_x\n",
    "                \n",
    "                # Estimate rotation from the cross product of position and flow vectors\n",
    "                rot = np.mean((x * flow[:,:,1] - y * flow[:,:,0]) / (x**2 + y**2 + 1e-8))\n",
    "                delta_angle = np.rad2deg(rot)\n",
    "                \n",
    "                # Update parameters\n",
    "                current_tx += dx\n",
    "                current_ty += dy\n",
    "                angle += delta_angle\n",
    "                \n",
    "                # Apply refined transformation\n",
    "                tform = AffineTransform(rotation=np.deg2rad(angle), \n",
    "                                       translation=(current_tx, current_ty))\n",
    "                moved = warp(mov_level, tform.inverse, mode='edge')\n",
    "            \n",
    "            # Update global parameters for next level\n",
    "            tx = current_tx / scale_factor\n",
    "            ty = current_ty / scale_factor\n",
    "        \n",
    "        # Apply final transformation to the original moving image\n",
    "        final_tform = AffineTransform(rotation=np.deg2rad(angle), \n",
    "                                     translation=(tx, ty))\n",
    "        aligned = warp(moving, final_tform.inverse, mode='edge')\n",
    "        \n",
    "        # Convert back to original dtype and range\n",
    "        if aligned.dtype != moving.dtype:\n",
    "            if moving.dtype == np.uint8:\n",
    "                aligned = (aligned * 255).astype(np.uint8)\n",
    "        \n",
    "        aligned_images.append(aligned)\n",
    "    \n",
    "    return aligned_images\n",
    "\n",
    "def crop_aligned_images(aligned_images, margin=20):\n",
    "    \"\"\"\n",
    "    Crop the aligned images to remove border artifacts.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    aligned_images : list of numpy arrays\n",
    "        List of aligned images\n",
    "    margin : int\n",
    "        Margin to crop from each edge\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    cropped_images : list of numpy arrays\n",
    "        List of cropped images\n",
    "    \"\"\"\n",
    "    h, w = aligned_images[0].shape[:2]\n",
    "    cropped_images = []\n",
    "    \n",
    "    for img in aligned_images:\n",
    "        cropped = img[margin:h-margin, margin:w-margin]\n",
    "        cropped_images.append(cropped)\n",
    "        \n",
    "    return cropped_images\n",
    "\n",
    "def align_and_average(image_paths, levels=3, iterations=10, margin=20):\n",
    "    \"\"\"\n",
    "    Align multiple images and compute their average.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    image_paths : list of str\n",
    "        List of paths to images\n",
    "    levels : int\n",
    "        Number of pyramid levels for alignment\n",
    "    iterations : int\n",
    "        Number of iterations per level\n",
    "    margin : int\n",
    "        Margin to crop from each edge\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    avg_image : numpy array\n",
    "        Averaged aligned image\n",
    "    aligned_images : list of numpy arrays\n",
    "        List of aligned images\n",
    "    \"\"\"\n",
    "    # Load images\n",
    "    images = [cv2.imread(path) for path in image_paths]\n",
    "    \n",
    "    # Align images\n",
    "    aligned_images = eulerian_motion_align(images, levels, iterations)\n",
    "    \n",
    "    # Crop images to remove border artifacts\n",
    "    cropped_images = crop_aligned_images(aligned_images, margin)\n",
    "    \n",
    "    # Compute average\n",
    "    avg_image = np.mean(np.array(cropped_images), axis=0)\n",
    "    \n",
    "    # Convert back to uint8 if necessary\n",
    "    if images[0].dtype == np.uint8:\n",
    "        avg_image = np.clip(avg_image, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return avg_image, cropped_images\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # List of image paths\n",
    "    image_paths = [\"1.jpg\", \"2.jpg\", \"3.jpg\"]\n",
    "    \n",
    "    # Align and average images\n",
    "    avg_image, aligned_images = align_and_average(image_paths)\n",
    "    \n",
    "    # Display results\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(cv2.imread(image_paths[0]), cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Reference Image\")\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(cv2.cvtColor(aligned_images[1], cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Aligned Image 1\")\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.imshow(cv2.cvtColor(aligned_images[2], cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Aligned Image 2\")\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(cv2.cvtColor(avg_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Averaged Result\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
